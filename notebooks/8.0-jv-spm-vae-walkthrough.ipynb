{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder: hyperparameter tuning, training and analysis.\n",
    "\n",
    "Repetimos el workflow implementado con el AutoEncoder Convolucional, pero ahora utilizando el modelo variacional. La idea es ver cómo difiere la representación de las unidades del espacio latente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.create_data import load_data\n",
    "from src.features.preprocess_data import to_dB, remove_outliers\n",
    "from src.models.saving import save_configuration\n",
    "from src.models.select_model import k_fold_cv\n",
    "from src.models.model_wrappers import build_cae_architecture\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ajuste de hiperparámetros\n",
    "\n",
    "Cargamos datos crudos, preprocesamos y separamos en conjuntos de entrenamiento y testeo. Luego hacemos un grid search para encontrar el mejor set de parámetros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos crudos\n",
    "raw_data = load_data(\"raw/spm_signatures_no_noise.npy\")\n",
    "print(f\"Shape de los datos: {raw_data.shape}\")\n",
    "\n",
    "# Removemos outliers y pasamos a dB\n",
    "data_dB = to_dB(remove_outliers(raw_data, k=100))\n",
    "print(f\"Número de muestras luego de remover outliers: {len(data_dB)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(\n",
    "    data_dB,\n",
    "    test_size=.2,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(f\"Tamaño de los datos de entrenamiento: {train_set.shape}\")\n",
    "print(f\"Tamaño de los datos de testeo: {test_set.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las posibles arquitecturas junto con el resto de los hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos la dimensión del espacio latente\n",
    "LATENT_DIMENTION = 3\n",
    "INPUT_SHAPE = train_set.shape[1:]\n",
    "\n",
    "# Configuracion de las capas convolucionales\n",
    "cv_layers = [\n",
    "    [(4, (7, 8), 2), (4, (5, 5), 1)],\n",
    "    [(4, (3, 4), 2), (4, (3, 3), 1)],\n",
    "    [(4, (3, 4), 2), (4, (3, 3), 1), (4, (3, 3), 1)],\n",
    "    [(4, (3, 4), 2), (4, (4, 4), 2), (4, (3, 3), 1)],\n",
    "    [(4, (3, 4), 2), (8, (3, 3), 1)],\n",
    "    [(4, (3, 3), 1), (4, (3, 3), 1)],\n",
    "    [(4, (3, 4), 2), (4, (4, 4), 2)],\n",
    "    [(4, (3, 4), 2), (16, (4, 4), 2)],\n",
    "    [(4, (3, 4), 2), (8, (4, 4), 2), (16, (3, 3), 1)],\n",
    "    [(4, (3, 4), 2), (4, (3, 3), 1), (4, (3, 3), 1), (4, (4, 4), 2)]\n",
    "]\n",
    "\n",
    "# Configuración de las capas densas\n",
    "dense_layers = [\n",
    "    (16,), (64,), (128), (256,),\n",
    "    (32, 16), (16, 16), (32, 32),\n",
    "    (256, 128), (256, 256)\n",
    " ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definida la grilla, iteramos sobre cada elemenro de la misma  y hacemos k-fold cross vaidation con k=5 para cada configuración. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero chequeamos que TensorFlow detecte la gpu\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations_score = []\n",
    "best_configuration = {'score' : 1e4}\n",
    "not_tested_configuration = []\n",
    "\n",
    "for cv_layer in tqdm(cv_layers):\n",
    "    for dense_layer in dense_layers:\n",
    "\n",
    "        # Configuración del modelo\n",
    "        conv_configuration = dict(\n",
    "            layers_config=cv_layer,\n",
    "            kernel_initializer= 'glorot_uniform'\n",
    "        )\n",
    "\n",
    "        dense_configuration = dict(\n",
    "            layers_units=dense_layer,\n",
    "        )                \n",
    "\n",
    "        configuration = {\n",
    "            'conv_layers_config': conv_configuration, \n",
    "            'dense_layers_config': dense_configuration, \n",
    "            'batch_size': 16\n",
    "        }\n",
    "\n",
    "        # k-fold cross validation\n",
    "        try:\n",
    "            k_fold_score = k_fold_cv(\n",
    "                train_set, build_cae_architecture, configuration\n",
    "            )\n",
    "        \n",
    "        except tf.errors.ResourceExhaustedError:\n",
    "            # En el caso de agotar los recursos\n",
    "            not_tested_configuration.append(configuration)\n",
    "            \n",
    "            warnings.warn(\n",
    "                ('La actual configuración agotó los recursos '\n",
    "                f'de memoria y no fue evaluada: \\n {configuration}'), \n",
    "                RuntimeWarning\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            # Actualizo los scores de las configuraciones\n",
    "            configuration.update(k_fold_score)\n",
    "            configurations_score.append(configuration)\n",
    "                \n",
    "            if configuration['score'] < best_configuration['score']:\n",
    "                best_configuration = configuration \n",
    "        \n",
    "        finally:\n",
    "            continue     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame.from_records(configurations_score).sort_values(by='score')\n",
    "df_scores['conv_layers_config'] = df_scores['conv_layers_config'].apply(lambda x: x['layers_config'])\n",
    "df_scores['dense_layers_config'] = df_scores['dense_layers_config'].apply(lambda x: x['layers_units'])\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo los scores y la arquitectura con mejor score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get resutls directory path\n",
    "src_dir = os.path.normpath(os.getcwd() + '/..')\n",
    "results_dir = os.path.join(src_dir, 'results/spm')\n",
    "\n",
    "# File name and dir\n",
    "file_name = 'vae_architectures_scores.pkl'\n",
    "file_dir = os.path.join(results_dir, file_name)\n",
    "\n",
    "# Save model_scores as pkl\n",
    "with open(file_dir, 'wb') as f:\n",
    "    pickle.dump(configurations_score, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved at /home/jotavecorta/proyectos/tesis/src/models/model_architecture_spm.json\n"
     ]
    }
   ],
   "source": [
    "save_configuration(\n",
    "    best_configuration, \n",
    "    filename='vae_architecture'\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos la mejor arquitectura, probamos agregar maxpooling, dropout, earlystopping y variar el learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "108e1cc6a60d66fe97f96d2e8e10d7bf778806389051764108cdd128ca1fcb58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
